{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcace480",
   "metadata": {},
   "source": [
    "## Deconvolution with Scaden\n",
    "\n",
    "Gemma Bel Bordes - 12/01/2024 - Python version I used: 3.10.12\n",
    "\n",
    "Original source code from https://scaden.readthedocs.io/en/latest/usage.html --> move `scaden/` to this directory\n",
    "\n",
    "But please note that I have modified 2 scripts to ensure reproducibility (since the simulation step produced different outputs due to randomness):\n",
    "- `scaden/simulate.py`\n",
    "- `scaden/simulation/bulk_simulator.py` \n",
    "\n",
    "You can find the changes by searching for #GBB (as a comment next to the added code).\n",
    "\n",
    "==> This notebook and these two modified files can be found here: https://github.com/gemmabb/DeconvolutionAtheroscleroticPlaques/tree/main/scadenModification\n",
    "\n",
    "Note also there are some folders you must create before this:\n",
    "- `generatedData/` \n",
    "- `generatedModels/`\n",
    "- `generatedPredictions/`\n",
    "- `input/` where there should be all the sc and bulk data you have (linear bulk and all sc by patient - see https://github.com/gemmabb/DeconvolutionAtheroscleroticPlaques/blob/main/DataProcessing.R)\n",
    "\n",
    "So you should be working with a working directory with this structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7c9c4",
   "metadata": {},
   "source": [
    "```\n",
    "├── 'Deconvolution with scaden'.ipynb #this notebook\n",
    "├── input\n",
    "│   ├── sc_byPatient \n",
    "│   │   ├── ae*_counts.txt\n",
    "│   │   ├── ae*_celltypes.txt\n",
    "│   ├── linearBulk_forScaden.txt\n",
    "├── generatedData\n",
    "├── generatedModels\n",
    "├── generatedPredictions\n",
    "├── scaden #source code from scaden\n",
    "    ├── example.py   \n",
    "    ├── __main__.py  \n",
    "    ├── model      \n",
    "    │   ├── architectures.py  \n",
    "    │   ├── functions.py\n",
    "    │   ├── __init__.py  \n",
    "    │   ├── scaden.py\n",
    "    ├── process.py   \n",
    "    ├── simulate.py #not the original, seed modification\n",
    "    ├── train.py\n",
    "    ├── __init__.py  \n",
    "    ├── merge.py\n",
    "    ├── predict.py  \n",
    "    ├── simulation\n",
    "    │   ├── __init__.py  \n",
    "    │   ├── bulk_simulator.py #not the original, seed modification\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f37f5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scaden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e4576bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 10:09:48.156588: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-12 10:09:48.159392: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-12 10:09:48.159404: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from scaden.train import training\n",
    "from scaden.predict import prediction\n",
    "from scaden.process import processing\n",
    "from scaden.simulate import simulation\n",
    "from scaden.merge import merge_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4eef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [112, 113, 122, 123, 132, 133, 213, 231, 312, 321]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3489c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate over 10 seeds, run 10 times (bc each simulation produces different data and final predictions, get average):\n",
    "\n",
    "for i in range(len(seeds)):\n",
    "    print(\"------ RUN:\", i+1, \"-------\")\n",
    "    #simulate per patient:\n",
    "    simulation(simulate_dir=\"generatedData/\", data_dir=\"./input/sc_byPatient/\", \n",
    "               sample_size=100, num_samples=1000, pattern=\"*_counts.txt\", unknown_celltypes=\"unknown\", \n",
    "               out_prefix=\"data\", fmt=\"txt\", seed=seeds[i]) #I added this last argument, seed\n",
    "\n",
    "    #merge datasets:\n",
    "    merge_datasets(\"generatedData/\", \"generatedData/data\"+str(seeds[i]))\n",
    "    ! rm generatedData/ae* #keep only merged data (ae* are those from each patient)\n",
    "\n",
    "    #process datasets before training:\n",
    "    processing(\"input/linearBulk_forScaden.txt\", \"generatedData/data\"+str(seeds[i])+\".h5ad\", \n",
    "               \"generatedData/processed\"+str(seeds[i])+\".h5ad\", var_cutoff=0.1)\n",
    "    ! rm generatedData/data* #keep only processed data (data* is the merged dataset)\n",
    "\n",
    "    #train the model:\n",
    "    training(\"mergedData/processed\"+str(seeds[i])+\".h5ad\", )\n",
    "    ! rm generatedData/* #remove all (there should be the processed data) for storage purposes \n",
    "\n",
    "    #make predictions:\n",
    "    prediction(model_dir=\"generatedModels/\", data_path=\"input/linearBulk_forScaden.txt\", \n",
    "               out_name=\"generatedPredictions/bothSex\"+str(seeds[i])+\"_scaden_predictions.txt\")\n",
    "    !rm -r generatedModels/* #remove models\n",
    "               \n",
    "    print(\"------ predictions stored as\" + \"generatedPredictions/bothSex\"+str(seeds[i])+\"_scaden_predictions.txt\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
